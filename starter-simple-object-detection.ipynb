{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\nVery basic version of custom object detection using pre trained model.","metadata":{}},{"cell_type":"markdown","source":"## Libraries ","metadata":{}},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport random\nimport os, csv\nimport numpy as np\nimport tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport random \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reproducibility","metadata":{}},{"cell_type":"code","source":"seed1=193\ntensorflow.random.set_seed(seed1)\nnp.random.seed(seed1)\nrandom.seed(seed1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data- Pre Processing\n* images and annotation (xml) files will be converted into csv format for smoother flow of the model training.","metadata":{}},{"cell_type":"code","source":"import cv2\na=cv2.imread(\"../input/simple-object-detection/datasets/images/a (101).jpg\",0)\nprint(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets_directory = \"../input/simple-object-detection/datasets\"\nannotations_directory=\"../input/simple-object-detection/datasets/annotations/\"\nformat='.jpg'\nN = []      \nfor r, d, f in os.walk(datasets_directory, topdown=False):\n    N.append(f)   \nK=np.arange(len(N[0]))\nrandom.shuffle(K)\nfor i in K:  \n    annotation_file=annotations_directory+N[0][i]\n    ds = BeautifulSoup(open(annotation_file).read(), \"html.parser\")\n    # Iterating each object elements\n    for o in ds.find_all(\"object\"):\n        class_label = o.find(\"name\").string\n        x_min = max(0, int(float(o.find(\"xmin\").string)))\n        y_min = max(0, int(float(o.find(\"ymin\").string)))\n        x_max = min(int(ds.find(\"width\").string), int(float(o.find(\"xmax\").string)))\n        y_max = min(int(ds.find(\"height\").string), int(float(o.find(\"ymax\").string)))\n        # controlling errors\n        if x_min >= x_max or y_min >= y_max:\n            continue\n        elif x_max <= x_min or y_max <= y_min:\n            continue\n        line = [N[1][i], str(x_min), str(y_min), str(x_max), str(y_max), str(class_label)]\n        with open(\"datasets.csv\", 'a', newline='') as f:\n                csv.writer(f).writerow(line)\nprint(\"datasets.csv has been created...\")","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Reading/Processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('datasets.csv',header = None,names=[\"image_tag\", \"left\", \"top\", \"right\",\"bottom\",'a'])\ndf=df.drop(['a'], axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalise locations (output coordinates)\ndf[\"left\"]=df[\"left\"]/224\ndf[\"top\"]=df[\"top\"]/224\ndf[\"right\"]=df[\"right\"]/224\ndf[\"bottom\"]=df[\"bottom\"]/224\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train and test split\nrt=0.2\nix=int((1-rt)*len(df))\ndf1 = df.iloc[:ix,:] \ndf2 = df.iloc[ix+1:,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255)\ntrain_g = datagen.flow_from_dataframe(\n    df1, directory='/kaggle/input/datasets/images/',\n    x_col=\"image_tag\",y_col=[\"left\", \"top\", \"right\",\"bottom\"],\n    target_size=(224, 224),batch_size=5, \n    class_mode=\"raw\",subset=\"training\")\nvalid_g = datagen.flow_from_dataframe(\n    df2, directory='/kaggle/input/datasets/images/',\n    x_col=\"image_tag\",y_col=[\"left\", \"top\", \"right\",\"bottom\"],\n    target_size=(224, 224),batch_size=5, \n    class_mode=\"raw\",subset=\"training\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Setup","metadata":{}},{"cell_type":"code","source":"# Model Setup\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(64, activation=\"relu\"))\nmodel.add(tf.keras.layers.Dense(4, activation=\"relu\"))\nmodel.summary()\nmodel.compile(tf.keras.optimizers.SGD(learning_rate=0.1),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"# Training\nmodel.fit(train_g, steps_per_epoch=17, validation_data=valid_g, validation_steps=4, epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\nThe star dectection datasets is created for study purpose. it can be developed further. \nThanks.","metadata":{}}]}